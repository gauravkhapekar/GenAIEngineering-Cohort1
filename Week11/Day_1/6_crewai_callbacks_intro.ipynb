{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrewAI Callbacks: Monitoring and Control\n",
    "\n",
    "Callbacks allow you to monitor agent execution and track progress in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crewai crewai-tools langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.tools import tool\n",
    "\n",
    "\n",
    "# Set your API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_ROUTER_KEY\")\n",
    "os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")\n",
    "os.environ['LITELLM_LOG'] = 'DEBUG' \n",
    "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
    "os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
    "\n",
    "\n",
    "# Initialize the language model\n",
    "llm = LLM(\n",
    "        model='openai/gpt-4o',\n",
    "        api_key=os.getenv('OPEN_ROUTER_KEY'),\n",
    "        base_url=\"https://openrouter.ai/api/v1\"\n",
    "    )\n",
    "\n",
    "# Global storage for callback data (in production, use proper storage)\n",
    "callback_logs = []\n",
    "performance_metrics = {}\n",
    "# Storage for logs\n",
    "callback_logs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Callbacks\n",
    "\n",
    "### Important: Callback Signatures\n",
    "\n",
    "The exact callback signatures can vary by CrewAI version. Common patterns:\n",
    "- `task_callback(output)` - Called when a task completes\n",
    "- `step_callback(step_output)` - Called for each step (may receive different object types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple task callback\n",
    "def task_callback(output):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] Task completed!\")\n",
    "    print(f\"Output length: {len(str(output))} characters\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Step callback - Fixed to handle different parameter types\n",
    "def step_callback(step_output):\n",
    "    \"\"\"Step callback that handles the output from each step.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    print(f\"[{timestamp}] Step executed\")\n",
    "    \n",
    "    # Check what type of output we received\n",
    "    output_type = type(step_output).__name__\n",
    "    print(f\"Output type: {output_type}\")\n",
    "    \n",
    "    # Show preview of output\n",
    "    if hasattr(step_output, '__dict__'):\n",
    "        print(f\"Attributes: {list(step_output.__dict__.keys())[:5]}...\")\n",
    "    else:\n",
    "        print(f\"Output preview: {str(step_output)[:100]}...\")\n",
    "\n",
    "# Safe wrapper for any callback - DEFINE THIS FIRST\n",
    "def make_safe_callback(callback_func):\n",
    "    \"\"\"Wraps any callback to handle errors gracefully.\"\"\"\n",
    "    def safe_wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return callback_func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Callback error handled: {type(e).__name__}: {e}\")\n",
    "            print(f\"Continuing execution...\")\n",
    "    return safe_wrapper\n",
    "\n",
    "# Flexible step callback that handles different parameter counts\n",
    "def flexible_step_callback(*args, **kwargs):\n",
    "    \"\"\"Step callback that adapts to different signatures.\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    print(f\"[{timestamp}] Step callback triggered\")\n",
    "    print(f\"Args received: {len(args)}\")\n",
    "    print(f\"Kwargs received: {list(kwargs.keys())}\")\n",
    "    \n",
    "    # Try to extract useful information\n",
    "    for i, arg in enumerate(args):\n",
    "        arg_type = type(arg).__name__\n",
    "        print(f\"  Arg {i}: {arg_type}\")\n",
    "        \n",
    "        # If it has a role attribute, it might be an agent\n",
    "        if hasattr(arg, 'role'):\n",
    "            print(f\"    - Role: {arg.role}\")\n",
    "        \n",
    "        # If it's a string or has string representation\n",
    "        if isinstance(arg, str) or hasattr(arg, '__str__'):\n",
    "            preview = str(arg)[:50]\n",
    "            print(f\"    - Preview: {preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Tools (with proper docstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool functions MUST have docstrings and type hints\n",
    "def search_func(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Found information about: {query}\"\n",
    "\n",
    "def analyze_func(data: str) -> str:\n",
    "    \"\"\"Analyze data.\"\"\"\n",
    "    return f\"Analysis of: {data}\"\n",
    "\n",
    "# Create tools\n",
    "search_tool = tool(\"Search\")(search_func)\n",
    "analyze_tool = tool(\"Analyze\")(analyze_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Agents and Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents\n",
    "researcher = Agent(\n",
    "    role=\"Researcher\",\n",
    "    goal=\"Find information\",\n",
    "    backstory=\"Expert researcher\",\n",
    "    tools=[search_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "analyst = Agent(\n",
    "    role=\"Analyst\",\n",
    "    goal=\"Analyze findings\",\n",
    "    backstory=\"Expert analyst\",\n",
    "    tools=[analyze_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Create tasks\n",
    "research_task = Task(\n",
    "    description=\"Research AI trends\",\n",
    "    expected_output=\"Research findings\",\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "analysis_task = Task(\n",
    "    description=\"Analyze the research\",\n",
    "    expected_output=\"Analysis report\",\n",
    "    agent=analyst\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Crew with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crew with callbacks\n",
    "crew = Crew(\n",
    "    agents=[researcher, analyst],\n",
    "    tasks=[research_task, analysis_task],\n",
    "    process=Process.sequential,\n",
    "    task_callback=task_callback,\n",
    "    step_callback=step_callback,  # Using the fixed step_callback\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Crew created with callbacks!\")\n",
    "\n",
    "# Alternative: Create crew with flexible callbacks\n",
    "flexible_crew = Crew(\n",
    "    agents=[researcher, analyst],\n",
    "    tasks=[research_task, analysis_task],\n",
    "    process=Process.sequential,\n",
    "    task_callback=make_safe_callback(task_callback),\n",
    "    step_callback=make_safe_callback(flexible_step_callback),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Alternative crew created with flexible callbacks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execute the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute crew\n",
    "print(\"Starting crew execution...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Try the standard crew first\n",
    "try:\n",
    "    result = crew.kickoff()\n",
    "    print(\"Standard crew executed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Standard crew failed: {e}\")\n",
    "    print(\"Trying flexible crew...\")\n",
    "    result = flexible_crew.kickoff()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Result preview: {str(result)[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance monitoring\n",
    "task_times = {}\n",
    "\n",
    "def performance_callback(output):\n",
    "    task_id = id(output)\n",
    "    if task_id not in task_times:\n",
    "        task_times[task_id] = time.time()\n",
    "    else:\n",
    "        duration = time.time() - task_times[task_id]\n",
    "        print(f\"Task completed in {duration:.2f}s\")\n",
    "\n",
    "# Data collector\n",
    "def collect_data(output):\n",
    "    global callback_logs\n",
    "    log = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'output': str(output)[:100]\n",
    "    }\n",
    "    callback_logs.append(log)\n",
    "    print(f\"Logged data (total logs: {len(callback_logs)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Callback Factory Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom callbacks\n",
    "def create_logger(level=\"INFO\"):\n",
    "    def logger(output):\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print(f\"[{level}] [{timestamp}] {str(output)[:50]}...\")\n",
    "    return logger\n",
    "\n",
    "# Create filter callback\n",
    "def create_filter(keyword):\n",
    "    def filter_callback(output):\n",
    "        if keyword.lower() in str(output).lower():\n",
    "            print(f\"Found '{keyword}' in output!\")\n",
    "    return filter_callback\n",
    "\n",
    "# Test factory functions\n",
    "info_logger = create_logger(\"INFO\")\n",
    "error_filter = create_filter(\"error\")\n",
    "\n",
    "info_logger(\"Test message\")\n",
    "error_filter(\"No error here\")\n",
    "error_filter(\"An error occurred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Combining Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiple callbacks\n",
    "def combine_callbacks(*callbacks):\n",
    "    def combined(output):\n",
    "        for cb in callbacks:\n",
    "            try:\n",
    "                cb(output)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in callback: {e}\")\n",
    "    return combined\n",
    "\n",
    "# Create combined callback\n",
    "multi_callback = combine_callbacks(\n",
    "    task_callback,\n",
    "    performance_callback,\n",
    "    collect_data,\n",
    "    create_logger(\"DEBUG\")\n",
    ")\n",
    "\n",
    "# Use with crew\n",
    "multi_crew = Crew(\n",
    "    agents=[researcher, analyst],\n",
    "    tasks=[research_task, analysis_task],\n",
    "    process=Process.sequential,\n",
    "    task_callback=multi_callback,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dashboard Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dashboard\n",
    "def create_dashboard():\n",
    "    stats = {'tasks': 0, 'start': time.time()}\n",
    "    \n",
    "    def dashboard(output):\n",
    "        stats['tasks'] += 1\n",
    "        elapsed = time.time() - stats['start']\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"DASHBOARD\")\n",
    "        print(f\"Tasks: {stats['tasks']}\")\n",
    "        print(f\"Time: {elapsed:.1f}s\")\n",
    "        print(f\"{'='*40}\\n\")\n",
    "    \n",
    "    return dashboard\n",
    "\n",
    "# Create and test dashboard\n",
    "dashboard = create_dashboard()\n",
    "dashboard(\"Test output 1\")\n",
    "time.sleep(1)\n",
    "dashboard(\"Test output 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe callback wrapper\n",
    "def safe_callback(callback_func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return callback_func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Callback error: {e}\")\n",
    "    return wrapper\n",
    "\n",
    "# Error tracking\n",
    "error_count = 0\n",
    "\n",
    "def error_tracker(output):\n",
    "    global error_count\n",
    "    if \"error\" in str(output).lower():\n",
    "        error_count += 1\n",
    "        print(f\"Error detected! Total: {error_count}\")\n",
    "\n",
    "# Make it safe\n",
    "safe_error_tracker = safe_callback(error_tracker)\n",
    "\n",
    "# Test\n",
    "safe_error_tracker(\"No problem\")\n",
    "safe_error_tracker(\"Error found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save logs to file\n",
    "def save_logs(filename=\"logs.json\"):\n",
    "    def saver(output):\n",
    "        log = {\n",
    "            'time': datetime.now().isoformat(),\n",
    "            'data': str(output)[:200]\n",
    "        }\n",
    "        try:\n",
    "            with open(filename, 'a') as f:\n",
    "                json.dump(log, f)\n",
    "                f.write('\\n')\n",
    "            print(f\"Saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Save error: {e}\")\n",
    "    return saver\n",
    "\n",
    "# Analyze logs\n",
    "def analyze_logs():\n",
    "    if not callback_logs:\n",
    "        print(\"No logs\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Total logs: {len(callback_logs)}\")\n",
    "    for i, log in enumerate(callback_logs[-5:]):\n",
    "        print(f\"{i+1}. {log['timestamp']}: {log['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Callback Errors\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "1. **'ToolResult' object has no attribute 'role'**\n",
    "   - The step_callback may receive different object types\n",
    "   - Use flexible callbacks that check object types\n",
    "\n",
    "2. **Wrong number of arguments**\n",
    "   - Callback signatures can vary by CrewAI version\n",
    "   - Use `*args, **kwargs` for flexibility\n",
    "\n",
    "3. **Callbacks breaking execution**\n",
    "   - Always wrap callbacks in error handlers\n",
    "   - Use the `make_safe_callback` wrapper\n",
    "\n",
    "### Debug Helper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug callback to understand what parameters are being passed\n",
    "def debug_callback(*args, **kwargs):\n",
    "    \"\"\"Use this to debug what parameters callbacks receive.\"\"\"\n",
    "    print(\"\\n=== DEBUG CALLBACK ===\")\n",
    "    print(f\"Number of args: {len(args)}\")\n",
    "    print(f\"Number of kwargs: {len(kwargs)}\")\n",
    "    \n",
    "    for i, arg in enumerate(args):\n",
    "        print(f\"\\nArg {i}:\")\n",
    "        print(f\"  Type: {type(arg)}\")\n",
    "        print(f\"  Value preview: {str(arg)[:100]}...\")\n",
    "        print(f\"  Attributes: {dir(arg)[:10]}...\")\n",
    "    \n",
    "    for key, value in kwargs.items():\n",
    "        print(f\"\\nKwarg '{key}':\")\n",
    "        print(f\"  Type: {type(value)}\")\n",
    "        print(f\"  Value: {str(value)[:100]}...\")\n",
    "    \n",
    "    print(\"\\n=== END DEBUG ===\")\n",
    "\n",
    "# Use debug callbacks to understand the signature\n",
    "debug_crew = Crew(\n",
    "    agents=[researcher],\n",
    "    tasks=[research_task],\n",
    "    process=Process.sequential,\n",
    "    task_callback=debug_callback,\n",
    "    step_callback=debug_callback,\n",
    "    verbose=False  # Reduce noise for debugging\n",
    ")\n",
    "\n",
    "print(\"Debug crew created - run it to see callback parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
