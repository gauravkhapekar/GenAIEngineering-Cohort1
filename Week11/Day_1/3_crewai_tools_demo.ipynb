{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrewAI Tools Demonstration: One Tool at a Time\n",
    "\n",
    "This notebook demonstrates how to use CrewAI agents with individual tools to showcase the unique value each tool brings to your AI crew.\n",
    "\n",
    "## üìã Table of Contents\n",
    "1. Setup and Installation\n",
    "2. Web Search Tool Demo\n",
    "3. Website Search Tool Demo\n",
    "4. File Operations Demo\n",
    "5. CSV Analysis Demo\n",
    "6. JSON Processing Demo\n",
    "7. PDF Search Demo\n",
    "8. Document Processing Demo\n",
    "9. YouTube Search Demo\n",
    "10. Combined Crew Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install crewai crewai-tools langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "env_vars_to_clear = ['OPENAI_API_KEY', 'OPENAI_BASE_URL', 'OPENAI_API_BASE']\n",
    "for var in env_vars_to_clear:\n",
    "    if os.getenv(var):\n",
    "        print(f\"‚ö†Ô∏è  Removing conflicting {var}\")\n",
    "        del os.environ[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai_tools import (\n",
    "    SerperDevTool,           # Web search\n",
    "    WebsiteSearchTool,       # Website-specific search\n",
    "    FileReadTool,            # File operations\n",
    "    DirectorySearchTool,     # Directory operations\n",
    "    CodeDocsSearchTool,      # Code documentation search\n",
    "    CSVSearchTool,           # CSV file operations\n",
    "    JSONSearchTool,          # JSON operations\n",
    "    XMLSearchTool,           # XML operations\n",
    "    TXTSearchTool,           # Text file operations\n",
    "    PDFSearchTool,           # PDF operations\n",
    "    DOCXSearchTool,          # Word document operations\n",
    "    MDXSearchTool,           # Markdown operations\n",
    "    YoutubeChannelSearchTool, # YouTube operations\n",
    "    YoutubeVideoSearchTool\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set API keys (replace with your actual keys)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_ROUTER_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_AI_KEY\")\n",
    "os.environ[\"SERPER_API_KEY\"] = os.getenv(\"SERPER_API_KEY\")\n",
    "# os.environ['LITELLM_LOG'] = 'DEBUG' \n",
    "# os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
    "# os.environ['OPENAI_BASE_URL'] = 'https://openrouter.ai/api/v1'\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Web Search Tool Demo\n",
    "\n",
    "**Value**: Enables agents to search the internet for current information, research topics, and gather real-time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a web search specialist agent\n",
    "web_search_tool = SerperDevTool()\n",
    "\n",
    "web_researcher = Agent(\n",
    "    role='Web Research Specialist',\n",
    "    goal='Find the most current and relevant information on any topic from the web',\n",
    "    backstory=\"\"\"You are an expert web researcher with years of experience in finding \n",
    "    accurate, up-to-date information online. You know how to craft effective search \n",
    "    queries and evaluate source credibility.\"\"\",\n",
    "    tools=[web_search_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create a research task\n",
    "research_task = Task(\n",
    "    description=\"\"\"Research the latest developments in quantum computing in 2024. \n",
    "    Find information about:\n",
    "    1. Recent breakthroughs\n",
    "    2. Leading companies and their progress\n",
    "    3. Practical applications being developed\n",
    "    \n",
    "    Provide a comprehensive summary with sources.\"\"\",\n",
    "    expected_output=\"A detailed report on quantum computing developments with cited sources\",\n",
    "    agent=web_researcher\n",
    ")\n",
    "\n",
    "# Execute the task\n",
    "crew = Crew(\n",
    "    agents=[web_researcher],\n",
    "    tasks=[research_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(\"\\nüìä Research Results:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Website Search Tool Demo\n",
    "\n",
    "**Value**: Enables deep searching within specific websites, perfect for documentation, company research, or domain-specific information gathering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a website-specific search agent\n",
    "website_tool = WebsiteSearchTool(website=\"https://docs.python.org\")\n",
    "\n",
    "documentation_expert = Agent(\n",
    "    role='Python Documentation Expert',\n",
    "    goal='Find specific information from Python documentation',\n",
    "    backstory=\"\"\"You are a Python documentation specialist who helps developers \n",
    "    find exactly what they need from the official Python docs. You understand \n",
    "    technical terminology and can explain complex concepts clearly.\"\"\",\n",
    "    tools=[website_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create a documentation search task\n",
    "doc_task = Task(\n",
    "    description=\"\"\"Search the Python documentation for information about:\n",
    "    1. How decorators work in Python\n",
    "    2. Best practices for using decorators\n",
    "    3. Examples of built-in decorators\n",
    "    \n",
    "    Provide clear explanations with code examples.\"\"\",\n",
    "    expected_output=\"A comprehensive guide on Python decorators from official documentation\",\n",
    "    agent=documentation_expert\n",
    ")\n",
    "\n",
    "# Execute\n",
    "doc_crew = Crew(\n",
    "    agents=[documentation_expert],\n",
    "    tasks=[doc_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "doc_result = doc_crew.kickoff()\n",
    "print(\"\\nüìö Documentation Findings:\")\n",
    "print(doc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. File Operations Demo\n",
    "\n",
    "**Value**: Enables agents to read and process local files, essential for working with existing documents and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create some sample files to work with\n",
    "import json\n",
    "\n",
    "# Create a sample text file\n",
    "with open('sample_report.txt', 'w') as f:\n",
    "    f.write(\"\"\"Q4 2024 Sales Report\n",
    "    \n",
    "Executive Summary:\n",
    "- Total Revenue: $2.5M (15% increase YoY)\n",
    "- New Customers: 450\n",
    "- Customer Retention: 92%\n",
    "- Top Product: Enterprise Suite\n",
    "\n",
    "Key Achievements:\n",
    "1. Launched new AI-powered features\n",
    "2. Expanded to 3 new markets\n",
    "3. Improved customer satisfaction score to 4.8/5\n",
    "\n",
    "Challenges:\n",
    "- Supply chain delays in Q4\n",
    "- Increased competition in APAC region\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Sample files created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file analysis agent\n",
    "file_tool = FileReadTool()\n",
    "\n",
    "file_analyst = Agent(\n",
    "    role='Business Intelligence Analyst',\n",
    "    goal='Analyze business documents and extract key insights',\n",
    "    backstory=\"\"\"You are a seasoned business analyst who excels at reading reports, \n",
    "    identifying trends, and providing actionable insights. You have a keen eye for \n",
    "    detail and can spot both opportunities and risks.\"\"\",\n",
    "    tools=[file_tool],\n",
    "    max_iter=1,\n",
    "    # verbose=True\n",
    ")\n",
    "\n",
    "# Create an analysis task\n",
    "analysis_task = Task(\n",
    "    description=\"\"\"Read and analyze the file 'sample_report.txt'. \n",
    "    Provide:\n",
    "    1. A summary of key metrics\n",
    "    2. An analysis of strengths and weaknesses\n",
    "    3. Recommendations for next quarter\n",
    "    4. Risk assessment based on the challenges mentioned\"\"\",\n",
    "    expected_output=\"A comprehensive analysis report with actionable recommendations\",\n",
    "    agent=file_analyst\n",
    ")\n",
    "\n",
    "# Execute\n",
    "file_crew = Crew(\n",
    "    agents=[file_analyst],\n",
    "    tasks=[analysis_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "file_result = file_crew.kickoff()\n",
    "print(\"\\nüìà Analysis Results:\")\n",
    "print(file_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CSV Analysis Demo\n",
    "\n",
    "**Value**: Enables data analysis, pattern recognition, and insights extraction from structured CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample CSV file\n",
    "import csv\n",
    "\n",
    "with open('sales_data.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Date', 'Product', 'Revenue', 'Units', 'Region'])\n",
    "    writer.writerow(['2024-01-15', 'Enterprise Suite', 45000, 15, 'North America'])\n",
    "    writer.writerow(['2024-01-16', 'Basic Plan', 5000, 50, 'Europe'])\n",
    "    writer.writerow(['2024-01-17', 'Enterprise Suite', 60000, 20, 'Asia'])\n",
    "    writer.writerow(['2024-01-18', 'Pro Plan', 15000, 30, 'North America'])\n",
    "    writer.writerow(['2024-01-19', 'Basic Plan', 3000, 30, 'Europe'])\n",
    "    writer.writerow(['2024-01-20', 'Enterprise Suite', 75000, 25, 'North America'])\n",
    "\n",
    "print(\"‚úÖ Sample CSV created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "        model='openai/gpt-4o',\n",
    "        api_key=os.getenv('OPEN_ROUTER_KEY'),\n",
    "        base_url=\"https://openrouter.ai/api/v1\"\n",
    "    )\n",
    "\n",
    "csv_tool = CSVSearchTool(csv='sales_data.csv')\n",
    "\n",
    "data_analyst = Agent(\n",
    "    role='Senior Data Analyst',\n",
    "    goal='Analyze CSV data to uncover trends and insights',\n",
    "    backstory=\"\"\"You are a data analysis expert with strong skills in identifying \n",
    "    patterns, calculating metrics, and providing data-driven recommendations. \n",
    "    You excel at turning raw data into actionable business intelligence.\"\"\",\n",
    "    tools=[csv_tool],\n",
    "    # verbose=True,\n",
    "    max_iter=1\n",
    "    # llm=llm\n",
    ")\n",
    "\n",
    "# Create a data analysis task\n",
    "csv_task = Task(\n",
    "    description=\"\"\"Analyze the sales_data.csv file and provide:\n",
    "    1. Total revenue by product\n",
    "    2. Best performing region\n",
    "    3. Average units sold per transaction\n",
    "    4. Identify any trends or patterns\n",
    "    5. Recommendations for sales strategy\"\"\",\n",
    "    expected_output=\"A detailed data analysis report with visualizations and recommendations\",\n",
    "    agent=data_analyst\n",
    ")\n",
    "\n",
    "# Execute\n",
    "csv_crew = Crew(\n",
    "    agents=[data_analyst],\n",
    "    tasks=[csv_task],\n",
    "    process=Process.sequential\n",
    "    # llm=llm\n",
    ")\n",
    "\n",
    "csv_result = csv_crew.kickoff()\n",
    "print(\"\\nüìä Data Analysis Results:\")\n",
    "print(csv_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. JSON Processing Demo\n",
    "\n",
    "**Value**: Enables processing of API responses, configuration files, and structured data in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create a sample JSON file\n",
    "import json\n",
    "\n",
    "api_data = {\n",
    "    \"users\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"Alice Johnson\",\n",
    "            \"subscription\": \"Enterprise\",\n",
    "            \"usage\": {\n",
    "                \"api_calls\": 15420,\n",
    "                \"storage_gb\": 245,\n",
    "                \"last_active\": \"2024-01-20\"\n",
    "            },\n",
    "            \"billing\": {\n",
    "                \"monthly_cost\": 499,\n",
    "                \"payment_method\": \"credit_card\",\n",
    "                \"status\": \"active\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"Bob Smith\",\n",
    "            \"subscription\": \"Pro\",\n",
    "            \"usage\": {\n",
    "                \"api_calls\": 5200,\n",
    "                \"storage_gb\": 50,\n",
    "                \"last_active\": \"2024-01-19\"\n",
    "            },\n",
    "            \"billing\": {\n",
    "                \"monthly_cost\": 99,\n",
    "                \"payment_method\": \"paypal\",\n",
    "                \"status\": \"active\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"name\": \"Carol Davis\",\n",
    "            \"subscription\": \"Basic\",\n",
    "            \"usage\": {\n",
    "                \"api_calls\": 980,\n",
    "                \"storage_gb\": 10,\n",
    "                \"last_active\": \"2024-01-15\"\n",
    "            },\n",
    "            \"billing\": {\n",
    "                \"monthly_cost\": 29,\n",
    "                \"payment_method\": \"credit_card\",\n",
    "                \"status\": \"pending\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"api_limits\": {\n",
    "        \"Enterprise\": {\"calls\": 100000, \"storage\": 1000},\n",
    "        \"Pro\": {\"calls\": 10000, \"storage\": 100},\n",
    "        \"Basic\": {\"calls\": 1000, \"storage\": 10}\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('user_data.json', 'w') as f:\n",
    "    json.dump(api_data, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Sample JSON created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON processing agent\n",
    "json_tool = JSONSearchTool(json_path='user_data.json')\n",
    "\n",
    "api_analyst = Agent(\n",
    "    role='API Usage Analyst',\n",
    "    goal='Analyze JSON data from APIs to monitor usage and identify issues',\n",
    "    backstory=\"\"\"You specialize in analyzing API usage data and user behavior. \n",
    "    You can quickly identify usage patterns, potential issues, and opportunities \n",
    "    for optimization from JSON-formatted data.\"\"\",\n",
    "    tools=[json_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create a JSON analysis task\n",
    "json_task = Task(\n",
    "    description=\"\"\"Analyze the user_data.json file and provide:\n",
    "    1. Usage statistics per subscription tier\n",
    "    2. Users approaching their API limits\n",
    "    3. Revenue analysis by subscription type\n",
    "    4. Identify any billing issues\n",
    "    5. Recommendations for user engagement\"\"\",\n",
    "    expected_output=\"A comprehensive API usage report with actionable insights\",\n",
    "    agent=api_analyst\n",
    ")\n",
    "\n",
    "# Execute\n",
    "json_crew = Crew(\n",
    "    agents=[api_analyst],\n",
    "    tasks=[json_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "json_result = json_crew.kickoff()\n",
    "print(\"\\nüîç JSON Analysis Results:\")\n",
    "print(json_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PDF Search Demo\n",
    "\n",
    "**Value**: Enables extraction and analysis of information from PDF documents, essential for processing reports, research papers, and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: For this demo, you would need an actual PDF file\n",
    "# Here's how you would use the PDF tool\n",
    "\n",
    "# Assuming you have a PDF file named 'research_paper.pdf'\n",
    "pdf_tool = PDFSearchTool(pdf='IndianBudget2025.pdf')  # Replace with your PDF\n",
    "\n",
    "research_analyst = Agent(\n",
    "    role='macro economist',\n",
    "    goal='Analyse the budget and summarize key findings',\n",
    "    backstory=\"\"\"You are an expert at reading and analyzing budget. \"\"\",\n",
    "    tools=[pdf_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create a PDF analysis task\n",
    "pdf_task = Task(\n",
    "    description=\"\"\"Provide a comprehensive summary.\"\"\",\n",
    "    expected_output=\"list key points in budget\",\n",
    "    agent=research_analyst\n",
    ")\n",
    "\n",
    "# This would execute if you have a PDF file\n",
    "pdf_crew = Crew(\n",
    "    agents=[research_analyst],\n",
    "    tasks=[pdf_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "pdf_result = pdf_crew.kickoff()\n",
    "\n",
    "print(\"\\nüìÑ PDF Tool configured (requires actual PDF file to execute)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Document Processing Demo (DOCX)\n",
    "\n",
    "**Value**: Enables processing of Word documents, perfect for analyzing reports, proposals, and business documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a document processing agent\n",
    "# Note: Requires an actual .docx file\n",
    "docx_tool = DOCXSearchTool(docx='proposal.docx')  # Replace with your file\n",
    "\n",
    "proposal_reviewer = Agent(\n",
    "    role='Business Proposal Reviewer',\n",
    "    goal='Review and analyze business proposals for completeness and quality',\n",
    "    backstory=\"\"\"You are an experienced business consultant who reviews proposals. \n",
    "    You ensure all key sections are present, the value proposition is clear, \n",
    "    and the proposal is compelling and professional.\"\"\",\n",
    "    tools=[docx_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create a document review task\n",
    "docx_task = Task(\n",
    "    description=\"\"\"Review the business proposal and check for:\n",
    "    1. Executive summary clarity\n",
    "    2. Problem statement definition\n",
    "    3. Proposed solution details\n",
    "    4. Budget and timeline\n",
    "    5. Risk assessment\n",
    "    \n",
    "    Provide feedback and suggestions for improvement.\"\"\",\n",
    "    expected_output=\"A detailed review with specific improvement recommendations\",\n",
    "    agent=proposal_reviewer\n",
    ")\n",
    "\n",
    "print(\"\\nüìù DOCX Tool configured (requires actual DOCX file to execute)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary: Tool Value Proposition\n",
    "\n",
    "### Each tool brings unique capabilities:\n",
    "\n",
    "1. **SerperDevTool**: Real-time web information\n",
    "2. **WebsiteSearchTool**: Deep domain-specific knowledge\n",
    "3. **FileReadTool**: Local document processing\n",
    "4. **CSVSearchTool**: Structured data analysis\n",
    "5. **JSONSearchTool**: API and configuration data processing\n",
    "6. **PDFSearchTool**: Research paper and report analysis\n",
    "7. **DOCXSearchTool**: Business document processing\n",
    "8. **YouTubeTools**: Video content analysis\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Match tools to agent expertise**: Give each agent tools that align with their role\n",
    "2. **Use context sharing**: Later tasks can build on earlier task results\n",
    "3. **Be specific in prompts**: Clear task descriptions lead to better results\n",
    "4. **Combine tools strategically**: Multi-agent crews can tackle complex projects\n",
    "5. **Monitor token usage**: Some tools (like PDF/video analysis) can be token-intensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Experiment with different tools**: Try each tool with your own data\n",
    "2. **Create custom agents**: Design agents for your specific use cases\n",
    "3. **Build complex crews**: Combine multiple agents for sophisticated workflows\n",
    "4. **Integrate with your systems**: Use these tools to automate real business processes\n",
    "\n",
    "Remember: The key to CrewAI's power is in thoughtful agent design and strategic tool selection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup sample files\n",
    "import os\n",
    "\n",
    "files_to_remove = ['sample_report.txt', 'sales_data.csv', 'user_data.json']\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        \n",
    "print(\"‚úÖ Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
